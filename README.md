# AI533 Intelligent Agents and Decision Making

* 2 Written Assignment
- HW1: MDP design, Mathematical expression, Value Iteration Convergence, The characteristics of Reward function, etc.
- HW2: SARSA, Reward Notations, Monte Carlo Prediction, Actor-Critic, The Value Calculation of First-visit, Every-visit Monte Carlo, Q-learning Proof 

* 2 Mini-projects
- MP1: Given MDP environment,
  <img width="221" alt="image" src="https://github.com/user-attachments/assets/23eb2b08-17a4-4c1f-ba3c-3cee29c2375f" />
  
  Part A: Implement Value Iteration and Policy Iteration.
  <img width="334" alt="image" src="https://github.com/user-attachments/assets/0fc68dff-aa49-43e5-8978-534939122911" />
  <img width="209" alt="image" src="https://github.com/user-attachments/assets/eecc81d1-42db-4406-8154-17563e6ae959" />


  Part B: Imitation Learning - Generate Trajectory and implement DAGGER algorithm
  
  <img width="340" alt="image" src="https://github.com/user-attachments/assets/050b93e7-16c0-4a38-a03b-a05ec9b6ce59" />
  <img width="301" alt="image" src="https://github.com/user-attachments/assets/fc10d778-57f6-43de-84f1-27bdf5c1a3ad" />

- MP2: Given MDP environment,
  Part A: TD Methods - Implement Tabular SARSA, Q-learning, SARSA(Î»)
  <img width="373" alt="image" src="https://github.com/user-attachments/assets/7ad7dc20-b8d7-4b79-a1cd-902a3e70a4f7" />
  <img width="368" alt="image" src="https://github.com/user-attachments/assets/1b8dc819-a5c3-41d0-b803-a1ca7dce53e1" />
  <img width="365" alt="image" src="https://github.com/user-attachments/assets/db6d77ca-e26c-4c0c-a59e-98b88a72dba2" />

  
  Part B: Actor-Critic - Implement Actor-Critic algorithm with a function approximator, Comparison it with others
  <img width="355" alt="image" src="https://github.com/user-attachments/assets/b522092a-67a0-4fac-92af-98d8db5a04f6" />
  <img width="368" alt="image" src="https://github.com/user-attachments/assets/79859ae8-9266-480f-9269-f01900f2e981" />

  
